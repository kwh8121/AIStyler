"""
Gemini API ì§ì ‘ ì—°ë™ êµì • ëª¨ë“ˆ
OpenAI API ê²½ë¡œì™€ ë™ì¼í•œ SSE í˜ì´ë¡œë“œ í˜•ì‹ì„ ìœ ì§€
"""

import json
import time
import logging
import pysbd
from typing import AsyncGenerator, List, Dict, Optional
from sqlalchemy.ext.asyncio import AsyncSession

from ...config import settings
from ...styleguides import service as style_guide_service
from ...styleguides.models import StyleCategory
from ..models import ArticleCategory
from .translation import translate_text
from .prompt_builder import (
    generate_openai_style_analysis_prompt,
    generate_openai_correction_prompt,
)

# ê¸°ì¡´ ë¤í”„ ìœ í‹¸ ì¬ì‚¬ìš©
from .openai_correction import dump_prompt

logger = logging.getLogger(__name__)


async def analyze_style_violations_gemini(
    text: str,
    category: ArticleCategory,
    style_guides: List,
    db: AsyncSession,
) -> Dict:
    """Gemini APIë¥¼ ì‚¬ìš©í•˜ì—¬ ìŠ¤íƒ€ì¼ê°€ì´ë“œ ìœ„ë°˜ ë¶„ì„(JSON êµ¬ì¡°í™” ì‘ë‹µ)."""
    try:
        from google import genai

        client = genai.Client(api_key=settings.GEMINI_API_KEY)

        analysis_prompt = generate_openai_style_analysis_prompt(style_guides, category.value)
        dump_prompt(
            "gemini_analysis",
            analysis_prompt,
            {
                "category": category.value,
                "style_guide_count": len(style_guides),
                "text_length": len(text),
            },
        )

        logger.info("ğŸ” Gemini analyzing style violations as JSON")

        # ê°„ë‹¨ JSON ìŠ¤í‚¤ë§ˆ(ì§€ì›ë˜ëŠ” OpenAPI subset)
        schema = {
            "type": "object",
            "properties": {
                "violations": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "rule_id": {"type": "string"},
                            "sentence_index": {"type": "integer"},
                        },
                        "required": ["rule_id", "sentence_index"],
                    },
                },
                "total_violations": {"type": "integer"},
            },
            "required": ["violations", "total_violations"],
        }

        response = client.models.generate_content(
            model=settings.GEMINI_MODEL or "gemini-2.5-flash",
            contents=[analysis_prompt, text],
            config={
                "response_mime_type": "application/json",
                "response_schema": schema,
            },
        )

        result_text = response.text or "{}"
        try:
            parsed = json.loads(result_text)
        except json.JSONDecodeError:
            logger.warning("Gemini analysis JSON parse failed; using empty violations")
            parsed = {"violations": [], "total_violations": 0}

        violations = parsed.get("violations", [])
        applicable_rules = list(set(v.get("rule_id", "") for v in violations if v.get("rule_id")))

        # DB style_ids ë§¤í•‘
        style_ids = []
        for guide in style_guides:
            for rule_id in applicable_rules:
                if f"SG{guide.number:03d}" in rule_id:
                    style_ids.append(guide.id)
                    break

        return {
            "violations": violations,
            "total_violations": len(violations),
            "applicable_rules": applicable_rules,
            "style_ids": style_ids,
        }

    except Exception as e:
        logger.error(f"Gemini style analysis failed: {e}")
        return {
            "violations": [],
            "total_violations": 0,
            "applicable_rules": [],
            "style_ids": [],
        }


async def call_gemini_correction_stream(
    prompt: Optional[str],
    text: str,
    category: ArticleCategory,
    db: AsyncSession,
) -> AsyncGenerator[str, None]:
    """
    Gemini APIë§Œì„ ì‚¬ìš©í•œ êµì • ìŠ¤íŠ¸ë¦¬ë° íŒŒì´í”„ë¼ì¸.
    - DeepL ë²ˆì—­(ìë™ ê°ì§€)
    - Gemini JSON ë¶„ì„
    - Gemini ìŠ¤íŠ¸ë¦¬ë° êµì •
    - OpenAI SSE í¬ë§·ê³¼ ë™ì¼í•œ ì´ë²¤íŠ¸ë¥¼ ìƒì„±
    """
    start_time = time.time()
    try:
        from google import genai

        client = genai.Client(api_key=settings.GEMINI_API_KEY)

        # Step 1. ë²ˆì—­
        yield json.dumps({"status": "translating", "message": "ë²ˆì—­ì¤‘..."})
        t0 = time.time()
        before_en, source_lang, target_lang = await translate_text(text, source_lang=None, target_lang="EN-US")
        t_translation = time.time() - t0
        yield json.dumps({"status": "translation_complete", "message": "ë²ˆì—­ ì™„ë£Œ", "elapsed": round(t_translation, 3)})

        # Step 2. ìŠ¤íƒ€ì¼ê°€ì´ë“œ ì¡°íšŒ
        category_map = {
            ArticleCategory.TITLE: StyleCategory.TITLE,
            ArticleCategory.SEO: StyleCategory.TITLE,
            ArticleCategory.BODY: StyleCategory.BODY,
            ArticleCategory.CAPTION: StyleCategory.CAPTION,
        }
        style_category = category_map.get(category, StyleCategory.BODY)
        style_guides = await style_guide_service.list_styleguides(db, category=style_category, limit=100)

        # Step 3. ë¶„ì„(JSON)
        yield json.dumps({"status": "applying_style", "message": "ìŠ¤íƒ€ì¼ ê°€ì´ë“œ ì ìš©ì¤‘..."})
        t1 = time.time()
        analysis = await analyze_style_violations_gemini(before_en, category, style_guides, db)
        t_analysis = time.time() - t1

        violations = analysis.get("violations", [])
        applicable_rules = analysis.get("applicable_rules", [])
        style_ids = analysis.get("style_ids", [])

        yield json.dumps({
            "type": "analysis",
            "data": {
                "applicable_rules": applicable_rules,
                "style_guide_violations": [
                    {"id": rid, "description": f"Style guide violation: {rid}"}
                    for rid in applicable_rules
                ],
                "style_ids": style_ids,
                "violations_count": len(violations),
            },
        })
        yield json.dumps({"status": "analysis_complete", "message": "ìŠ¤íƒ€ì¼ ê°€ì´ë“œ ë¶„ì„ ì™„ë£Œ"})

        # Step 4. êµì •(ìŠ¤íŠ¸ë¦¬ë°)
        full_corrected_text = before_en
        if violations or (prompt and prompt.strip()):
            correction_prompt = generate_openai_correction_prompt(before_en, violations, style_guides, prompt)
            dump_prompt(
                "gemini_correction",
                correction_prompt,
                {
                    "category": category.value,
                    "violations": len(violations),
                    "style_ids": style_ids,
                    "text_length": len(before_en),
                },
            )

            t2 = time.time()
            collected: List[str] = []

            stream = client.models.generate_content_stream(
                model=settings.GEMINI_MODEL or "gemini-2.5-flash",
                contents=[correction_prompt],
                config={
                    # í•„ìš” ì‹œ ì˜¨ë„/í† í° ë“± ì„¸ë¶€ê°’ ë…¸ì¶œ ê°€ëŠ¥
                },
            )

            for chunk in stream:
                delta_text = getattr(chunk, "text", None)
                if not delta_text:
                    continue
                collected.append(delta_text)
                yield json.dumps({
                    "type": "delta",
                    "data": {"choices": [{"delta": {"content": delta_text}}]},
                })

            full_corrected_text = "".join(collected)
            t_correction = time.time() - t2
        else:
            # ìœ„ë°˜ ì—†ìŒ: ì›ë¬¸ì„ ê·¸ëŒ€ë¡œ ìŠ¤íŠ¸ë¦¬ë°
            for ch in before_en:
                yield json.dumps({
                    "type": "delta",
                    "data": {"choices": [{"delta": {"content": ch}}]},
                })
            t_correction = 0.0

        # Step 5. ë¬¸ì¥ë³„ êµì • ì •ë³´
        seg = pysbd.Segmenter(language="en", clean=False)
        original_sentences = seg.segment(before_en)
        corrected_sentences = seg.segment(full_corrected_text)

        sentence_corrections = {}
        for idx in range(min(len(original_sentences), len(corrected_sentences))):
            sentence_violations = [
                v["rule_id"] for v in violations if v.get("sentence_index") == idx
            ]
            sentence_corrections[idx] = {
                "original": original_sentences[idx] if idx < len(original_sentences) else "",
                "corrected": corrected_sentences[idx] if idx < len(corrected_sentences) else "",
                "violations": sentence_violations,
            }

        yield json.dumps({
            "type": "sentence_corrections",
            "data": {
                "sentence_corrections": sentence_corrections,
                "total_sentences": len(original_sentences),
                "corrected_sentences": len(corrected_sentences),
                "full_text": full_corrected_text,
            },
        })
        yield json.dumps({"status": "sentence_parsing_complete", "message": "ë¬¸ì¥ë³„ êµì • íŒŒì‹± ì™„ë£Œ"})

        # Step 6. ìµœì¢… ìš”ì•½(ë²ˆì—­ ì •ë³´ í¬í•¨)
        total_time = time.time() - start_time
        final_analysis = {
            "applicable_rules": applicable_rules,
            "style_ids": style_ids,
            "sentence_corrections": sentence_corrections,
            "full_text": full_corrected_text,
            "translation": {
                "before_text": before_en,
                "source_lang": source_lang,
                "target_lang": target_lang,
            },
            "processing_time": {
                "translation": t_translation,
                "analysis": t_analysis,
                "correction": t_correction,
                "total": total_time,
            },
        }
        yield json.dumps({"type": "final_analysis", "data": final_analysis})
        yield json.dumps({"status": "complete", "message": "êµì • ì™„ë£Œ"})

    except Exception as e:
        logger.error(f"Gemini correction stream error: {e}")
        yield json.dumps({"type": "error", "data": {"message": f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"}})
        raise
